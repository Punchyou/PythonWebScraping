# **The requests package will be to download web pages, a tool for doing all things HTTP in Python.

The simple_get() attempts to get the content at 'url' by making an HTTP GET request.
The closing() function ensures that any network resources are freed when they go out of scope in that with block.

To start selecting and extracting, we use the BeautifulSoup library. 
The BeautifulSoup constructor parses raw HTML strings and produces an object that mirrors the HTML documentâ€™s structure.
The standard back-end parser is 'html.parser'.

The use of json.dumps is for pretty printing the data.

"""Returns True if the response seems to be HTML, False otherwise."""
"""Downloads the page where expected data are found and returns a list of strings."""
""" Finds points, author names, comments and ranks from html."""
""" Makes a list of all the data that retrieved from the html."""
print_engine() Creates the desired output format.

Type "python hacker_news_scraping.py" in a terminal, to run.
